###### tags: `李宏毅機器學習`
# 李宏毅機器學習第3集-機器學習任務攻略

# 第三集

# 1. Framework of ML

## 1.1 訓練資料與測試資料

![](https://i.imgur.com/EyUdqTz.png)
>意思是在作業給的data中x是輸入，y是輸出的結果
>test data只有輸入

## 1.2 訓練的過程

![](https://i.imgur.com/k25D2Zq.png)



1. 寫出一個有未知參數的 function，參數用 $\theta$ 來表示
2. 確定損失函數，判斷 function 的參數 $\theta$ 好不好
3. optimization，得到使損失函數最小的參數 $\theta^*$ 

# 2. 想要model做的更好該怎麼辦

![](https://i.imgur.com/sweRa7V.png)
>先檢查traning data的loss

## 2.1 train data上的 Loss

### 2.1.1 先檢查Model Bias

![](https://i.imgur.com/Dbn4x68.png)



所有設不同參數的function沒有可以讓loss變得足夠低
⇒ **可以讓 loss 變低的 function 不在 model 可以描述的範圍內**

⇒ **解決方法：重新設計一個 Model**，一個更複雜的、更有彈性的、有未知參數的、需要更多 features 的 function

### 2.1.2 Optimization(找loss的過程的方法)


![](https://i.imgur.com/GsF50zH.png)


gradient descent可能會卡在 local minima（局部極小值/鞍點）的地方，沒有辦法找到真的可以讓 loss 很低的參數

### 2.1.3 如何區分兩種情況？

- Start from shallower networks (or other models), which are easier to train.
    
    看到一個從來沒有做過的問題，可以先跑一些比較小、比較淺的 network，或甚至用一些不是 deep learning 的方法(linear model,SVM)  ⇒ **比較容易做 optimize**，**較不會有 optimization 失敗的問題**
    
- If deeper networks do not obtain smaller loss on training data, then there is optimization issue.
    
    如果發現深的 model 跟淺的 model 比起來，**深的 model 明明彈性比較大**，**loss 卻沒有辦法比淺的 model 壓得更低**，那就代表 **optimization 有問題**(因為深的明明bias可以比較大，可以更擬合，結果還比較爛，就表示是optimization的問題)
    

## 2.2 如train data沒問題，則看test data上的 Loss

### 2.2.1 Overfitting

**training 的 loss 小，testing 的 loss大，才有可能是 overfitting**。如果你的 model 它的**自由度很大**的話，它會**產生非常奇怪的曲線**，導致訓練集上的結果好，但是測試集上的 loss 很大
>這裡的overfitting是因為taining data太少了，導致模型都以少部分的data去擬合，所以就會過擬合在training data上，就是訓練的不夠精細，不夠擬合
>>而另一種是模型複雜度過高，可以把有一些太特別的輸入會把不相干的特徵也擷取，或是過於極端的資料

![](https://i.imgur.com/xMpR3W6.png)


**解決：**

1. 增加訓練集

雖然你的 model 它的彈性可能很大，但是因為數據樣本非常非常的多，它就可以限制住，更接近問題的曲線。

可自己創造資料:
**Data Augmentation：用一些對於問題的理解，從已有的數據中創造出新的數據（注意合理性）**

![](https://i.imgur.com/kjacFD9.png)
>(左右翻轉，放大...)

2. 限制模型，使之不要有那麼大的彈性

![](https://i.imgur.com/aQQefSI.png)
>例如:真正的曲線是二次式，利用對問題的理解，制定function為二次式，那他就更有可能跟真正的曲線一樣



有哪些方法可以給model限制:
- 給**比較少的參數（比如神經元的數目）**；**模型共用參數 (**[03-CNN](https://www.notion.so/03-CNN-86e7f137fdd0494fb08f236d34c67b6e)**)**
>限制在比較小的範圍，例如CNN就限制在影像的範圍內
- 使用**比較少的 features**
- Early Stopping(如loss function幾次無變動則停)
- Regularization(正規化)
- Dropout

## 2.3 不要加過大的彈性 ⇒ Model bias

![](https://i.imgur.com/gQubefL.png)
>太限制了，結果那三個點沒有一個直線可以表示，結果又回到model bias的問題(沒有深度可以表達問題的function)


## 2.4 Bias-Complexity Trade-off

![](https://i.imgur.com/nyaWzmj.png)


所謂比較複雜，是它可以**包含的 function 比較多，它的參數比較多，這個就是一個比較複雜的 model**

隨著 model 越來越複雜，**training 的 loss 可以越來越低，**當 model 越來越複雜的時候，剛開始 **testing 的 loss 會跟著下降**；但是當複雜的程度超過某一個程度以後，**testing 的 loss 就突然暴增**

## 2.5 Cross Validation
在作業中，可以將訓練集分成training data和validation data以避免在public data上overfitting，並且基本上不管public 上分數怎樣就不要去動他了 

![](https://i.imgur.com/BFckI1p.png)


1. 把 training 的資料分成兩部分，一部分叫作 training set，一部分是 validation set
2. 在 validation set 上面去衡量它們的分數，根據 validation set 上面的分數去挑選結果，不要管在 public testing set 上的結果以避免 overfiting

## 2.6 N-fold Cross Validation
如果擔心validation set切到奇怪的部分可以使用這個方法

**N-fold Cross Validation** 就是先把訓練集切成 N 等份，切完以後拿其中一份當作 Validation Set，另外 N-1 份當 training set，重覆 N 次
>切的部分輪流當validation set

![](https://i.imgur.com/4ZFRL67.png)


而現在有多個model要測試(這裡舉例三個)，每個model在每個不同的切等份執行，並且平均分數，挑選做得最好的那個模型(這裡是Model 1)，之後直接把model 1用在所有training data上(不用再validation set了)，然後再用在testing set上

## 2.7 Mismatch

訓練集跟測試集的分佈是不一樣的，依照對數據本身的理解來判斷

![](https://i.imgur.com/WW57Emh.png)
